{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJxK7xTliAIx"
      },
      "source": [
        "# Training Notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ECE-GY 7123 / CS-GY 6953 / Deep Learning - Fall '25 - Final Project\n",
        "\n",
        "**Team:** Spline Reticulator\n",
        "\n",
        "**Author/Member:** Thanh Do (qd2121@nyu.edu)"
      ],
      "metadata": {
        "id": "60P7cRAmrwqc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkVzxF-BiuZT"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0YhnFXYsi0X",
        "outputId": "9d3e1cfc-0ba9-4896-937d-65c733471a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: coverage in /usr/local/lib/python3.12/dist-packages (7.13.0)\n",
            "Requirement already satisfied: xmlschema in /usr/local/lib/python3.12/dist-packages (4.2.0)\n",
            "Requirement already satisfied: elementpath<6.0.0,>=5.0.1 in /usr/local/lib/python3.12/dist-packages (from xmlschema) (5.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install coverage xmlschema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Mn6mjtmivdy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import sys\n",
        "import coverage\n",
        "import xmlschema\n",
        "import math\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B36gJDDSDIhx",
        "outputId": "897e70d7-02db-4361-a748-4ce5cd17112c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up7F-ihdiAmM"
      },
      "source": [
        "## Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CqLQe_8hrOS7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seed(seed = 0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(123456)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Y2muNMzquM"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "icylihCUzsJF"
      },
      "outputs": [],
      "source": [
        "# Base model name\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "# W3C dataset\n",
        "DATA_DIR = \"./dataset\"\n",
        "# New token limit to fit inside VRAM\n",
        "MAX_NEW_TOKENS = 256\n",
        "# Cap total number of samples that we'll use for training\n",
        "MAX_DATASET_LENGTH = 4096\n",
        "# Maximum length for the tokenizer\n",
        "MAX_LENGTH = 1024\n",
        "\n",
        "# LoRA parameters\n",
        "LORA_RANK = 8\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.05\n",
        "\n",
        "# Training parameters\n",
        "OPTIMIZER = \"adamw_torch\"\n",
        "EPOCHS = 15\n",
        "LR = 2e-4\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_STEPS = 5\n",
        "\n",
        "# Evaluation parameters\n",
        "# Numbers of XML files to be sampled from the models\n",
        "GENERATE_COUNT = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ESpaCpidvu"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMQqMVf83zzH",
        "outputId": "0f9d28da-85e3-4ce4-a2b9-1b636975e6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-18 18:22:17--  https://github.com/w3c/xsdtests/archive/refs/heads/master.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/w3c/xsdtests/zip/refs/heads/master [following]\n",
            "--2025-12-18 18:22:17--  https://codeload.github.com/w3c/xsdtests/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [           <=>      ]  26.15M  12.5MB/s    in 2.1s    \n",
            "\n",
            "2025-12-18 18:22:19 (12.5 MB/s) - ‘master.zip’ saved [27425403]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/w3c/xsdtests/archive/refs/heads/master.zip\n",
        "!unzip -q master.zip\n",
        "!mv xsdtests-master/ dataset\n",
        "!rm master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "__VEowiMifnh"
      },
      "outputs": [],
      "source": [
        "def minify_xml(content):\n",
        "  \"\"\"\n",
        "  Removes comments and spaces between tags from a XML file.\n",
        "  \"\"\"\n",
        "  import re\n",
        "  content = re.sub(r'<!--.*?-->', '', content, flags=re.DOTALL)\n",
        "  content = re.sub(r'>\\s+<', '><', content)\n",
        "  return content\n",
        "\n",
        "def load_and_process_data(tokenizer):\n",
        "  \"\"\"\n",
        "  Globs and loads all XML/XSD files from the dataset.\n",
        "  \"\"\"\n",
        "  print(f\"Loading XML/XSD files from {DATA_DIR}...\")\n",
        "  files = glob.glob(f\"{DATA_DIR}/**/*.xsd\", recursive=True)\n",
        "\n",
        "  data = []\n",
        "  print(f\"Found {len(files)} files.\")\n",
        "  skipped = 0\n",
        "  processed = 0\n",
        "\n",
        "  random.shuffle(files)\n",
        "\n",
        "  for f_path in files:\n",
        "    try:\n",
        "      with open(f_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        content = minify_xml(f.read())\n",
        "        # Only train on XML schemas\n",
        "        if '\"http://www.w3.org/2001/XMLSchema\"' not in content:\n",
        "          skipped += 1\n",
        "          continue\n",
        "        processed += 1\n",
        "        # Ensure that we don't truncate anything\n",
        "        tokens = tokenizer.encode(content, add_special_tokens=True)\n",
        "        if len(tokens) < MAX_NEW_TOKENS:\n",
        "          data.append({\"text\": content})\n",
        "          if len(data) >= MAX_DATASET_LENGTH:\n",
        "            break\n",
        "        else:\n",
        "          skipped += 1\n",
        "    except Exception:\n",
        "      continue\n",
        "\n",
        "  print(f\"Processed {processed} samples, skipped {skipped} samples.\")\n",
        "\n",
        "  full_dataset = Dataset.from_list(data)\n",
        "  split_dataset = full_dataset.train_test_split(test_size=0.1) # 10% for Validation\n",
        "\n",
        "  return split_dataset[\"train\"], split_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIQ8WbIejFmg"
      },
      "source": [
        "## Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1UxIhRs6jINL"
      },
      "outputs": [],
      "source": [
        "def extract_first_xml_block(text):\n",
        "  \"\"\"\n",
        "  Extracts the first complete XML document, including Declaration/Doctype.\n",
        "  1. Finds the first '<'.\n",
        "  2. Tracks depth starting from the first actual Element.\n",
        "  3. Stops when that Root Element closes.\n",
        "  \"\"\"\n",
        "  # 1. Find the very first '<' (Skip leading whitespace/text)\n",
        "  start_match = re.search(r'<', text)\n",
        "  if not start_match:\n",
        "    return None\n",
        "\n",
        "  start_index = start_match.start()\n",
        "\n",
        "  # 2. Regex to identify XML structures\n",
        "  # Groups:\n",
        "  # 1. Comments/Declarations/Doctype: <!-- ... --> OR <? ... ?> OR <! ... >\n",
        "  # 2. Closing Tag: </ ... >\n",
        "  # 3. Self-Closing Tag: < ... />\n",
        "  # 4. Opening Tag: < ... >\n",
        "  tag_pattern = re.compile(\n",
        "    r'(<!--.*?-->|<\\?.*?\\?>|<![^>]*>)|(</[^>]+>)|(<[^>]+/>)|(<[^>]+>)',\n",
        "    re.DOTALL\n",
        "  )\n",
        "\n",
        "  depth = 0\n",
        "  root_found = False\n",
        "\n",
        "  # We scan starting from the first '<'\n",
        "  # match.end() gives us the position in the original string\n",
        "  for match in tag_pattern.finditer(text, pos=start_index):\n",
        "    full_tag = match.group(0)\n",
        "\n",
        "    # Group 1: Meta-tags (Comments, <?xml?>, <!DOCTYPE>)\n",
        "    if match.group(1):\n",
        "      # These exist at depth 0 but don't start the root element structure\n",
        "      continue\n",
        "\n",
        "    # Group 2: Closing Tag </foo>\n",
        "    elif match.group(2):\n",
        "      if root_found:\n",
        "        depth -= 1\n",
        "        if depth == 0:\n",
        "          # ROOT CLOSED! Return everything up to this character\n",
        "          return text[start_index:match.end()]\n",
        "      else:\n",
        "        # Found a closing tag before an opening one? Malformed.\n",
        "        return None\n",
        "\n",
        "    # Group 3: Self-Closing Tag <foo />\n",
        "    elif match.group(3):\n",
        "      if not root_found:\n",
        "        # If this is the first element, it's the root. And it ends here.\n",
        "        return text[start_index:match.end()]\n",
        "      # If we are inside root, it's just a child, depth unchanged.\n",
        "\n",
        "    # Group 4: Opening Tag <foo>\n",
        "    elif match.group(4):\n",
        "      if not root_found:\n",
        "        root_found = True\n",
        "        depth = 1\n",
        "      else:\n",
        "        depth += 1\n",
        "\n",
        "  # If loop finishes and we didn't return, the file is truncated/incomplete\n",
        "  return None\n",
        "\n",
        "def generate_samples(model, tokenizer, save_folder, prefix=\"gen\", gen_cnt=GENERATE_COUNT):\n",
        "  \"\"\"\n",
        "  Generates samples and saves them to a folder.\n",
        "  \"\"\"\n",
        "  print(f\"Generating {gen_cnt} samples into {save_folder}...\")\n",
        "  os.makedirs(save_folder, exist_ok=True)\n",
        "  model.eval()\n",
        "\n",
        "  # Prompts to trigger XSD generation (hopefully)\n",
        "  prompts = [\n",
        "    \"<?xml version=\",\n",
        "    \"<xs:schema\",\n",
        "  ]\n",
        "\n",
        "  attempt = 0\n",
        "  saved_count = 0\n",
        "  pbar = tqdm(total=gen_cnt)\n",
        "\n",
        "  while saved_count < gen_cnt:\n",
        "    attempt += 1\n",
        "    prompt = prompts[saved_count % len(prompts)]\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=MAX_NEW_TOKENS,\n",
        "        do_sample=True,\n",
        "        temperature=0.8,\n",
        "        top_p=0.8,\n",
        "        top_k=20,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "\n",
        "      generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "      generated_text = extract_first_xml_block(generated_text)\n",
        "      if generated_text is None:\n",
        "        # Break if we're stuck\n",
        "        if attempt >= (4 * gen_cnt):\n",
        "          print(\"WARN: We're unable to generate enough valid samples.\")\n",
        "          break\n",
        "        continue\n",
        "\n",
        "      # Save to file\n",
        "      with open(f\"{save_folder}/{prefix}_{saved_count}.xml\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(generated_text)\n",
        "\n",
        "      # Update progress bar\n",
        "      pbar.update(1)\n",
        "      saved_count += 1\n",
        "\n",
        "  pbar.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAM_K6rekzg"
      },
      "source": [
        "## Coverage Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qNo0kolEenXE"
      },
      "outputs": [],
      "source": [
        "from xmlschema import XMLSchema10, XMLSchema11\n",
        "\n",
        "XMLSchema10.meta_schema.build()\n",
        "XMLSchema11.meta_schema.build()\n",
        "\n",
        "def run_coverage_on_files(file_list, description):\n",
        "    print(f\"\\n--- Testing {description} ({len(file_list)} files) ---\")\n",
        "\n",
        "    # Initialize coverage\n",
        "    cov = coverage.Coverage(source=[\"xmlschema\"])\n",
        "    cov.start()\n",
        "\n",
        "    valid_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    for xml_file in file_list:\n",
        "        try:\n",
        "            # We try to validate the file.\n",
        "            # We expect errors (it's a fuzzer!), but we want to see\n",
        "            xmlschema.XMLSchema(xml_file)\n",
        "            valid_count += 1\n",
        "        except Exception:\n",
        "            # This is expected. We just want the code paths executed.\n",
        "            error_count += 1\n",
        "\n",
        "    cov.stop()\n",
        "\n",
        "    print(f\"Valid XMLs: {valid_count} | Invalid/Errors: {error_count}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    percent = cov.report(show_missing=False, file=sys.stdout)\n",
        "    return percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ddTjW8if83"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "  MODEL_NAME,\n",
        "  dtype=\"auto\",\n",
        "  device_map=\"auto\",\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "12e13bc464144c758e5bafe7e1650e68",
            "8a4b4d18553f4c4f9997f1ad9884a6b9",
            "3dd7fadbc9fb4f71a70058ea408fded8",
            "c1554399343749068919fb5d48b1bbcc",
            "932e895a081e47b89f775e0b50c34dd8",
            "83b41c1d143040babf8f26a2f7f1a416",
            "dbc20be01b1d40e3a6d987a5f32134ba",
            "b94729f1af784a4aadf27a298a6d2874",
            "b5efbd87abe44c8996d881d65ad91beb",
            "a9aacb3eb87c48e694747802c6425b8c",
            "275adfaa3d4f42e283bfdaf921a429ba",
            "7a353a93127c4faa81ac3bf6c16d81a7",
            "34432fd09ad54309b8a3b2d5e50afd0a",
            "9a68013d197a406e8952241c35f7314e",
            "81c2b64d8271411fa2009cb4232813c2",
            "3ef760d8ca814b1eba33c65053847cb1",
            "ec9227eca0c74181ad74a8a31f33279f",
            "133660285d8943629e116780a39a0b94",
            "6a01b6b59e73403ea3986bbb7c88825d",
            "058396b2a4b748c88b5fb3d2b87e9e91",
            "2e39dafec1324abf92acf842c85bada0",
            "0f4b33d36b2246e3977d5d76d53b59ff",
            "cd746d0277094c9d909e1192b1913047",
            "0d1de47bb66646d987b59299910fc001",
            "8f54b6a417a84196ba6a2ca18f10ec48",
            "a7fa8e7a2ceb4446b2e9d510ca3b5862",
            "67f6abb8b95744759949ee865d653163",
            "565232aae1834f86992c11ac3fd059ce",
            "1b22777bac164ab8a8c113077dce4311",
            "b1e605bb4e8e43198815f900dff22de1",
            "ea1fe55364a3434db11944cb9fc77918",
            "aace3087d25c400fb2a3a7a982d91cd6",
            "8ebc2391d3894ea2adad8ce873a9358a",
            "fac6fbb355024209b18ac508e4c8ac26",
            "eec71a190f174059bbcf0e6b5d21038f",
            "26c9b643757e41cd81a427c1105b5053",
            "8c7c62d648884c2e981b9d2ece420fe0",
            "7e121d647caf473c864b2c09f82844a5",
            "92360d09cd634115bcaba101bcd5ab0f",
            "13999c8676d141fe903aefd3a01fc166",
            "c6004da1b0434030ac6fca471fc1eb94",
            "e916862beacf4998b42d4a2782e77f06",
            "eef6373768ee4992984ee3af6eaf6ffe",
            "15691d357fc84c8285d4098e2ee0fd83",
            "7fe5edd50c664c18890717a82e398bc6",
            "928d52b0228c43339918efb2d95dc78e",
            "db15406772f149748079a873d4be57da",
            "5c4378cd094349bd96030f71fa55d4a6",
            "f2712e815499445490c7830bba0a5526",
            "36eca59ac17945bfa75b97a26ef8df70",
            "2291f619a13d4c26a7e67a1a71ea5933",
            "f99e516223db4982a4f98be9206225f7",
            "181d4f84533143f9a499c39a028bab41",
            "5976aaa6a4e543e3b96306092914c638",
            "4cb3ff5b2f1446c085dac7916f74aae4",
            "7511235433ef42d4aceb88053a880c6b",
            "0ee759f4810a4ea2b785cc3ee2e1dc11",
            "1f47f7e22437401fabe8445b73552212",
            "0daaf2826d2242519fc581f88e4b2b75",
            "c56595db52c5447bbe9c94f36ff9a23b",
            "6e0fef54bc024c5fa18315b3a097c322",
            "3f804a1e6a584f139e9d3f0ddeb1e6ec",
            "6757cd515ddc4e42ae81a9f358c9e1d0",
            "e7aad2ad129b4bd28278b4d11f1d5c83",
            "8118c889e49f4508bc5eb41700884c76",
            "0e7a44be0de94744af148118271ca9d5",
            "b5847317bda64ea6911ec0c3700342a7",
            "f9d4919669fb44bea9a506bd736e8ce5",
            "4c197e3ae852463a993176946132fd98",
            "e7b357112e1a4496a4c46203f608bb70",
            "f5c2d6707a02496c8b50d6e1530c49e5",
            "3e168082c4ba41a4b867ac49d3fbbdab",
            "ca603af2f50446b0bde29716bb055c8c",
            "afee3c2c9f0c45f192c7d8e0a13db363",
            "6354cf2d476540baa9f257a2cbc556f0",
            "142a6d5ea06d44fca21f8d0b948e3426",
            "113a8b9ee6f74dd78fc124b72bcd493b"
          ]
        },
        "id": "iqh7OzY7_BnX",
        "outputId": "86c48265-adb4-44d6-f229-b7b08c75a7ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12e13bc464144c758e5bafe7e1650e68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a353a93127c4faa81ac3bf6c16d81a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd746d0277094c9d909e1192b1913047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fac6fbb355024209b18ac508e4c8ac26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fe5edd50c664c18890717a82e398bc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7511235433ef42d4aceb88053a880c6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5847317bda64ea6911ec0c3700342a7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxiPa6FVilPp",
        "outputId": "1972e3d7-47f7-4107-acc6-346fc679cd09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 1: Zero-Shot Baseline ---\n",
            "Generating 100 samples into baseline_samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [27:33<00:00, 16.54s/it]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Phase 1: Zero-Shot Baseline ---\")\n",
        "generate_samples(base_model, tokenizer, f\"baseline_samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3UcK_jrer5M"
      },
      "source": [
        "### Evaluate Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpdfofYSeuLT",
        "outputId": "cf0bd499-5f22-415d-9459-5d1ce11a235a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Zero-Shot Baseline (100 files) ---\n",
            "Valid XMLs: 1 | Invalid/Errors: 99\n",
            "Name                                                                              Stmts   Miss  Cover\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/__init__.py                        20     20     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/_limits.py                          4      4     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/aliases.py                         70     70     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/arguments.py                      283    242    14%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/cli.py                            151    151     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/__init__.py             21     19    10%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/abdera.py               94     94     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/badgerfish.py           94     94     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/base.py                233    233     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/columnar.py            111    111     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/gdata.py               113    113     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/jsonml.py               70     70     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/parker.py               84     84     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/unordered.py            56     56     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/dataobjects.py                    298    298     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/documents.py                      252    252     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/exceptions.py                      22     22     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/exports.py                        227    227     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/__init__.py                  0      0   100%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/codegen.py                 353    353     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/wsdl.py                    442    442     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/limits.py                          33     33     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/loaders.py                        236    219     7%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/locations.py                       54     45    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/names.py                          155    155     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/namespaces.py                     226    196    13%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/__init__.py               4      4     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/fetchers.py              44     44     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/parsers.py               69     69     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/sax.py                   50     50     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/xml_loader.py           265    199    25%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/xml_resource.py         434    362    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/settings.py                       130    124     5%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/__init__.py                17     17     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_builders.py              449    449     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_factory.py               131    131     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_helpers.py               124    124     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_observers.py              58     58     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_test_case_classes.py     113    113     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/translation.py                     23     21     9%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/__init__.py                   0      0   100%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/decoding.py                  60     56     7%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/descriptors.py               32     32     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/etree.py                    163    158     3%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/logger.py                    55     55     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/misc.py                      53     52     2%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/paths.py                    100     71    29%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/protocols.py                  7      7     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/qnames.py                   104     81    22%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/streams.py                   98     97     1%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/urls.py                     141    120    15%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/__init__.py             19     19     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/assertions.py           83     83     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/attributes.py          522    463    11%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/builders.py            491    424    14%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/builtins.py             20     20     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/complex_types.py       663    651     2%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/elements.py           1038    905    13%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/exceptions.py          253    226    11%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/facets.py              497    486     2%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/groups.py             1017    939     8%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/helpers.py             163    158     3%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/identities.py          350    319     9%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/models.py              569    471    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/notations.py            22     22     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/particles.py           127    115     9%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/schemas.py             864    730    16%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/simple_types.py       1027    942     8%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/validation.py          288    244    15%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/wildcards.py           579    579     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/xsd_globals.py         415    313    25%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/xsdbase.py             468    410    12%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/__init__.py                   6      6     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/assertion_parser.py          11     11     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/identity_parser.py            5      5     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/mixin.py                    134    134     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/proxy.py                     46     46     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/selectors.py                137    137     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/xpath3.py                    11     11     0%\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "TOTAL                                                                             16251  14966     8%\n"
          ]
        }
      ],
      "source": [
        "baseline_files = glob.glob(f\"./baseline_samples/*.xml\")\n",
        "base_score = run_coverage_on_files(baseline_files, \"Zero-Shot Baseline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvKVTnexils1"
      },
      "source": [
        "## Post-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898,
          "referenced_widgets": [
            "5ba85ed568e4440e9e4b74d388cfe0c2",
            "542ade85f0ce4dc989a4e5033e87d1d6",
            "50405418baa04939b1ed3fc3b6600105",
            "de2d2f74e6e7418ca500349c7c60d143",
            "1d648a5ec2584525a26578ab743048ae",
            "640dbdcecd564c4d9f1fb94220e77777",
            "c0efc4d9cde84a45956652d8c952060d",
            "ddc19fa3412744428b0a3739dd9a16da",
            "ca20f83bda094f1aa0dd77fea1d39199",
            "7ac633d35535448e8b130fb269f3c7f3",
            "7ebd2ff15170435fb595a4675338ad83",
            "2cd81ae5f01b4bf6ad426b42358f0ff2",
            "a32e48eb383541ab86865f90497780a1",
            "73e28124b9554020a2e01b66c3f7b4a7",
            "6f0fbc0b30df40df84bbc3ce6dd7c5b8",
            "748fc0fd6eb04253a89a24c6749c3bd8",
            "41766f1354e04409a6cfe305e8a7847f",
            "0ca71d48802449ae962c4a0d710df344",
            "bec72eee142642259703dbc62d06e638",
            "a37565dd09764a2f8123635ea4096920",
            "0d3ac805c4c8430e895fd4ec6277fe8a",
            "e7479d09324e4a8d98f4d481b3dfb981"
          ]
        },
        "id": "3y3n0cEzirVv",
        "outputId": "3c693585-06a3-4f29-df0d-61bf00e5c3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 2: LoRA Post-Trained ---\n",
            "trainable params: 5,046,272 || all params: 601,096,192 || trainable%: 0.8395\n",
            "Loading XML/XSD files from ./dataset...\n",
            "Found 15464 files.\n",
            "Processed 7004 samples, skipped 4906 samples.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3686 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba85ed568e4440e9e4b74d388cfe0c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/410 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cd81ae5f01b4bf6ad426b42358f0ff2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3465' max='3465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3465/3465 1:27:51, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.289300</td>\n",
              "      <td>0.289744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255400</td>\n",
              "      <td>0.239701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.194700</td>\n",
              "      <td>0.217499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.151600</td>\n",
              "      <td>0.212891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.141400</td>\n",
              "      <td>0.208672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.123500</td>\n",
              "      <td>0.206000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.115500</td>\n",
              "      <td>0.215266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>0.213791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.090200</td>\n",
              "      <td>0.215265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.084200</td>\n",
              "      <td>0.220822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.083400</td>\n",
              "      <td>0.227846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.076700</td>\n",
              "      <td>0.225236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.080400</td>\n",
              "      <td>0.232029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.236318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.241672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing Final Perplexity...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52/52 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================\n",
            "Final Validation Loss: 0.2060\n",
            "Final Perplexity:      1.23\n",
            "=======================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Phase 2: LoRA Post-Trained ---\")\n",
        "\n",
        "# Prepare LoRA Config\n",
        "peft_config = LoraConfig(\n",
        "  task_type=TaskType.CAUSAL_LM,\n",
        "  inference_mode=False,\n",
        "  r=LORA_RANK,\n",
        "  lora_alpha=LORA_ALPHA,\n",
        "  lora_dropout=LORA_DROPOUT,\n",
        "  target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Prepare Data\n",
        "train_data, eval_data = load_and_process_data(tokenizer)\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
        "tokenized_eval = eval_data.map(tokenize_function, batched=True)\n",
        "\n",
        "# Trainer\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=f\"./checkpoints\",\n",
        "  per_device_train_batch_size=4,\n",
        "  gradient_accumulation_steps=4, # Simulates larger batch size\n",
        "  learning_rate=LR,\n",
        "  num_train_epochs=EPOCHS,\n",
        "  logging_steps=10,\n",
        "  fp16=(device==\"cuda\"),\n",
        "  optim=OPTIMIZER,\n",
        "  weight_decay=WEIGHT_DECAY,\n",
        "  warmup_steps=WARMUP_STEPS,\n",
        "  eval_strategy=\"epoch\", # Evaluate at end of every epoch\n",
        "  save_strategy=\"epoch\",\n",
        "  load_best_model_at_end=True, # Keep the best model (lowest loss)\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False,\n",
        "  report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  train_dataset=tokenized_train,\n",
        "  eval_dataset=tokenized_eval,\n",
        "  data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nComputing Final Perplexity...\")\n",
        "eval_results = trainer.evaluate()\n",
        "eval_loss = eval_results[\"eval_loss\"]\n",
        "perplexity = math.exp(eval_loss)\n",
        "\n",
        "print(f\"\\n=======================================\")\n",
        "print(f\"Final Validation Loss: {eval_loss:.4f}\")\n",
        "print(f\"Final Perplexity:      {perplexity:.2f}\")\n",
        "print(f\"=======================================\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlds7_AL4kSV"
      },
      "source": [
        "## Evaluate Post-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHiCg0v04mcD",
        "outputId": "31e46a02-ad52-4d4d-b7e2-9d3c43bfcea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 100 samples into lora_samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [34:40<00:00, 20.81s/it]\n"
          ]
        }
      ],
      "source": [
        "generate_samples(model, tokenizer, f\"lora_samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH4FCQVsirow"
      },
      "source": [
        "## Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnpbEWQPitDH",
        "outputId": "eb9db848-4f0f-4b86-f741-2fc42ff9cfe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing LoRA (100 files) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3658674033.py:20: XMLSchemaImportWarning: Import of namespace 'http://www.w3.org/XML' from ['file:///content/lora_samples/attgC.xsd'] failed: can't access to resource 'file:///content/lora_samples/attgC.xsd': [Errno 2] No such file or directory: '/content/lora_samples/attgC.xsd'.\n",
            "  xmlschema.XMLSchema(xml_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid XMLs: 15 | Invalid/Errors: 85\n",
            "Name                                                                              Stmts   Miss  Cover\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/__init__.py                        20     20     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/_limits.py                          4      4     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/aliases.py                         70     70     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/arguments.py                      283    238    16%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/cli.py                            151    151     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/__init__.py             21     19    10%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/abdera.py               94     94     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/badgerfish.py           94     94     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/base.py                233    233     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/columnar.py            111    111     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/gdata.py               113    113     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/jsonml.py               70     70     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/parker.py               84     84     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/converters/unordered.py            56     56     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/dataobjects.py                    298    298     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/documents.py                      252    252     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/exceptions.py                      22     22     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/exports.py                        227    227     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/__init__.py                  0      0   100%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/codegen.py                 353    353     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/extras/wsdl.py                    442    442     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/limits.py                          33     33     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/loaders.py                        236    181    23%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/locations.py                       54     45    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/names.py                          155    155     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/namespaces.py                     226    194    14%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/__init__.py               4      4     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/fetchers.py              44     44     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/parsers.py               69     69     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/sax.py                   50     50     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/xml_loader.py           265    199    25%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/resources/xml_resource.py         434    360    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/settings.py                       130    124     5%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/__init__.py                17     17     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_builders.py              449    449     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_factory.py               131    131     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_helpers.py               124    124     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_observers.py              58     58     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/testing/_test_case_classes.py     113    113     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/translation.py                     23     21     9%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/__init__.py                   0      0   100%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/decoding.py                  60     56     7%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/descriptors.py               32     32     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/etree.py                    163    157     4%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/logger.py                    55     55     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/misc.py                      53     52     2%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/paths.py                    100     69    31%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/protocols.py                  7      7     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/qnames.py                   104     71    32%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/streams.py                   98     97     1%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/utils/urls.py                     141    114    19%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/__init__.py             19     19     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/assertions.py           83     83     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/attributes.py          522    390    25%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/builders.py            491    393    20%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/builtins.py             20     20     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/complex_types.py       663    532    20%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/elements.py           1038    819    21%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/exceptions.py          253    208    18%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/facets.py              497    482     3%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/groups.py             1017    849    17%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/helpers.py             163    153     6%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/identities.py          350    311    11%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/models.py              569    433    24%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/notations.py            22     22     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/particles.py           127     97    24%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/schemas.py             864    727    16%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/simple_types.py       1027    894    13%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/validation.py          288    236    18%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/wildcards.py           579    509    12%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/xsd_globals.py         415    297    28%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/validators/xsdbase.py             468    391    16%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/__init__.py                   6      6     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/assertion_parser.py          11     11     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/identity_parser.py            5      5     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/mixin.py                    134    134     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/proxy.py                     46     46     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/selectors.py                137    137     0%\n",
            "/usr/local/lib/python3.12/dist-packages/xmlschema/xpath/xpath3.py                    11     11     0%\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "TOTAL                                                                             16251  14247    12%\n"
          ]
        }
      ],
      "source": [
        "lora_files = glob.glob(f\"./lora_samples/*.xml\")\n",
        "lora_score = run_coverage_on_files(lora_files, \"LoRA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artifact Checkpointing"
      ],
      "metadata": {
        "id": "mWjtbEASbpnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JRPOJ_t48UTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca9baaa-80b2-4a04-8c5d-ecc6399cdd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint and tokenizer saved to: /content/drive/MyDrive/xml_lora_model\n"
          ]
        }
      ],
      "source": [
        "# Define the path to save the model checkpoint in Google Drive\n",
        "save_path = '/content/drive/MyDrive/xml_lora_model'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Model checkpoint and tokenizer saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yDfEVVzjAXyd"
      },
      "outputs": [],
      "source": [
        "!cp -r baseline_samples /content/drive/MyDrive/baseline_samples\n",
        "!cp -r lora_samples /content/drive/MyDrive/lora_samples"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
