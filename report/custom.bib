% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@article{schulman2025lora,
  author = {John Schulman and Thinking Machines Lab},
  title = {LoRA Without Regret},
  journal = {Thinking Machines Lab: Connectionism},
  year = {2025},
  note = {https://thinkingmachines.ai/blog/lora/},
  doi = {10.64434/tml.20250929},
}

@article{midterm_report,
  author = {Thanh Do},
  title = {Midterm Project Report - Team: Spline Reticulator},
  journal = {ECE-GY 7123 / CS-GY 6953 / Deep Learning - Fall '25},
  year = {2025},
  url = {https://github.com/chitoge/qd2121_dl_midterm/releases/download/0.1.2/acl_latex.pdf},
}

@article{qwen3,
  title={Qwen3: Think Deeper, Act Faster},
  author={{Qwen Team}},
  year={2025},
  url={https://qwenlm.github.io/blog/qwen3/},
}

@misc{xmlschema,
  title={XML Schema Part 1: Structures Second Edition},
  author={Thompson, Henry S and others},
  year={2004},
  howpublished={W3C Recommendation},
  url={https://www.w3.org/TR/xmlschema-1/},
}

@misc{deng2023largelanguagemodelszeroshot,
      title={Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models}, 
      author={Yinlin Deng and Chunqiu Steven Xia and Haoran Peng and Chenyuan Yang and Lingming Zhang},
      year={2023},
      eprint={2212.14834},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2212.14834}, 
}

@inproceedings{Xia_2024, series={ICSE ’24},
   title={Fuzz4All: Universal Fuzzing with Large Language Models},
   url={http://dx.doi.org/10.1145/3597503.3639121},
   DOI={10.1145/3597503.3639121},
   booktitle={Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
   publisher={ACM},
   author={Xia, Chunqiu Steven and Paltenghi, Matteo and Le Tian, Jia and Pradel, Michael and Zhang, Lingming},
   year={2024},
   month=apr, pages={1–13},
   collection={ICSE ’24} }

@misc{godefroid2017learnfuzzmachinelearninginput,
      title={Learn&Fuzz: Machine Learning for Input Fuzzing}, 
      author={Patrice Godefroid and Hila Peleg and Rishabh Singh},
      year={2017},
      eprint={1701.07232},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1701.07232}, 
}

@inproceedings{10.1007/978-3-032-09524-4_1,
author = {Donaldson, Alastair F. and Cadar, Cristian and Carrasco, Manuel and Iorga, Dan and Liew, Daniel and Wickerson, John},
title = {When You Have a Fuzzer, Everything Looks Like a Reachability Problem},
year = {2025},
isbn = {978-3-032-09523-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-032-09524-4_1},
doi = {10.1007/978-3-032-09524-4_1},
abstract = {We provide an overview of three projects that explore the idea of using coverage-guided fuzzing, a technique traditionally used for finding bugs in software, in unconventional domains: (1) efficiently solving SMT formulas that use floating-point constraints; (2) achieving fast SMT sampling for such formulas; and (3) simulating operational memory models. In each case, the idea is to reduce the problem at hand into a reachability problem: transforming a problem instance into a program equipped with a special error location, such that finding an input that reaches the error location equates to finding a solution to the problem instance. Coverage-guided fuzzing, which excels at mutating a corpus of inputs to achieve increasing statement coverage of a system under test, can then be used to search for an input that reaches the error location—i.e., for a solution to the problem instance. We hope this overview will inspire other researchers to consider recasting search problems into a reachability problem form where coverage-guided fuzzing may prove effective.},
booktitle = {Reachability Problems: 19th International Conference, RP 2025, Madrid, Spain, October 1–3, 2025, Proceedings},
pages = {3–16},
numpages = {14},
keywords = {Coverage-guided fuzzing, constraint solving, floating point, memory models},
location = {Madrid, Spain}
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@inproceedings{huang-etal-2024-demystifying,
    title = "Demystifying Verbatim Memorization in Large Language Models",
    author = "Huang, Jing  and
      Yang, Diyi  and
      Potts, Christopher",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.598/",
    doi = "10.18653/v1/2024.emnlp-main.598",
    pages = "10711--10732",
    abstract = "Large Language Models (LLMs) frequently memorize long sequences verbatim, often with serious legal and privacy implications. Much prior work has studied such verbatim memorization using observational data. To complement such work, we develop a framework to study verbatim memorization in a controlled setting by continuing pre-training from Pythia checkpoints with injected sequences. We find that (1) non-trivial amounts of repetition are necessary for verbatim memorization to happen; (2) later (and presumably better) checkpoints are more likely to verbatim memorize sequences, even for out-of-distribution sequences; (3) the generation of memorized sequences is triggered by distributed model states that encode high-level features and makes important use of general language modeling capabilities. Guided by these insights, we develop stress tests to evaluate unlearning methods and find they often fail to remove the verbatim memorized information, while also degrading the LM. Overall, these findings challenge the hypothesis that verbatim memorization stems from specific model weights or mechanisms. Rather, verbatim memorization is intertwined with the LM{'}s general capabilities and thus will be very difficult to isolate and suppress without degrading model quality."
}

@inproceedings{10.1145/3510003.3510230,
author = {B\"{o}hme, Marcel and Szekeres, L\'{a}szl\'{o} and Metzman, Jonathan},
title = {On the reliability of coverage-based fuzzer benchmarking},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510230},
doi = {10.1145/3510003.3510230},
abstract = {Given a program where none of our fuzzers finds any bugs, how do we know which fuzzer is better? In practice, we often look to code coverage as a proxy measure of fuzzer effectiveness and consider the fuzzer which achieves more coverage as the better one.Indeed, evaluating 10 fuzzers for 23 hours on 24 programs, we find that a fuzzer that covers more code also finds more bugs. There is a very strong correlation between the coverage achieved and the number of bugs found by a fuzzer. Hence, it might seem reasonable to compare fuzzers in terms of coverage achieved, and from that derive empirical claims about a fuzzer's superiority at finding bugs.Curiously enough, however, we find no strong agreement on which fuzzer is superior if we compared multiple fuzzers in terms of coverage achieved instead of the number of bugs found. The fuzzer best at achieving coverage, may not be best at finding bugs.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1621–1633},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}
